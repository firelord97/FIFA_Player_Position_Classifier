{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the training dataset:\n",
      "     value_eur  wage_eur  age  height_cm  weight_kg  club_jersey_number  \\\n",
      "0  181500000.0  230000.0   24        182         75                 7.0   \n",
      "1  185000000.0  340000.0   22        195         94                 9.0   \n",
      "2  103000000.0  350000.0   32        181         75                17.0   \n",
      "3   41000000.0   23000.0   36        169         67                10.0   \n",
      "4   51000000.0   95000.0   35        185         81                 9.0   \n",
      "\n",
      "   weak_foot  skill_moves  attacking_crossing  attacking_finishing  ...  \\\n",
      "0          4            5                  78                   94  ...   \n",
      "1          3            3                  47                   96  ...   \n",
      "2          5            4                  95                   85  ...   \n",
      "3          4            4                  83                   89  ...   \n",
      "4          4            4                  75                   91  ...   \n",
      "\n",
      "   body_type_Lean (170-185)  body_type_Lean (185+)  body_type_Normal (170-)  \\\n",
      "0                         0                      0                        0   \n",
      "1                         0                      0                        0   \n",
      "2                         0                      0                        0   \n",
      "3                         0                      0                        0   \n",
      "4                         0                      0                        0   \n",
      "\n",
      "   body_type_Normal (170-185)  body_type_Normal (185+)  \\\n",
      "0                           0                        0   \n",
      "1                           0                        0   \n",
      "2                           0                        0   \n",
      "3                           0                        0   \n",
      "4                           1                        0   \n",
      "\n",
      "   body_type_Stocky (170-)  body_type_Stocky (170-185)  \\\n",
      "0                        0                           0   \n",
      "1                        0                           0   \n",
      "2                        0                           0   \n",
      "3                        0                           0   \n",
      "4                        0                           0   \n",
      "\n",
      "   body_type_Stocky (185+)  body_type_Unique  first_position  \n",
      "0                        0                 1              14  \n",
      "1                        0                 1              14  \n",
      "2                        0                 1               4  \n",
      "3                        0                 1               3  \n",
      "4                        0                 0               3  \n",
      "\n",
      "[5 rows x 64 columns]\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Mean Squared Error: 7.940639269406392\n",
      "All tasks completed successfully. Models and graphs are saved in their respective directories.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, learning_curve, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create directories if they don't exist\n",
    "graphs_dir = 'graphs_svm'\n",
    "models_dir = 'models_svm'\n",
    "os.makedirs(graphs_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'fifa_players_processed.csv'\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# List of columns to save for post-analysis\n",
    "post_analysis_columns = [\n",
    "    'player_id', 'overall', 'potential', 'club_team_id', 'league_name', \n",
    "    'nationality_name', 'st', 'lw', 'cf', 'rw', 'cam', 'lm', 'cm', 'rm', \n",
    "    'lwb', 'cdm', 'rwb', 'lb', 'cb', 'rb', 'gk', 'alternative_positions'\n",
    "]\n",
    "\n",
    "# Separate the post-analysis columns\n",
    "post_analysis_data = data[post_analysis_columns]\n",
    "\n",
    "# Drop the post-analysis columns from the main dataset\n",
    "data_cleaned = data.drop(columns=post_analysis_columns)\n",
    "\n",
    "# Ensure there are no NaNs in 'first_position'\n",
    "assert data_cleaned['first_position'].isnull().sum() == 0, \"There are NaNs in the 'first_position' column.\"\n",
    "\n",
    "# Encode the target feature 'first_position' as categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(data_cleaned['first_position'])\n",
    "\n",
    "# Save the label encoder classes for later use in confusion matrix\n",
    "label_classes = label_encoder.classes_\n",
    "\n",
    "# Drop the original 'first_position' column from the cleaned data\n",
    "X = data_cleaned.drop(columns=['first_position'])\n",
    "\n",
    "# Combine the cleaned data with the target labels\n",
    "data_for_training = X.copy()\n",
    "data_for_training['first_position'] = y_labels\n",
    "\n",
    "# Save the post-analysis dataset to a CSV file\n",
    "post_analysis_file_path = 'fifa_post_analysis.csv'\n",
    "post_analysis_data.to_csv(post_analysis_file_path, index=False)\n",
    "\n",
    "# Save the training dataset to a CSV file\n",
    "training_file_path = 'fifa_training_data.csv'\n",
    "data_for_training.to_csv(training_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the training dataset\n",
    "print(\"\\nFirst few rows of the training dataset:\")\n",
    "print(data_for_training.head())\n",
    "\n",
    "# Load training data\n",
    "data_path = 'fifa_training_data.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "X = data.drop('first_position', axis=1)\n",
    "y = data['first_position']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale']  # Only used for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Save the best model\n",
    "best_model_path = os.path.join(models_dir, 'best_model_svm.joblib')\n",
    "joblib.dump(grid_search.best_estimator_, best_model_path)\n",
    "\n",
    "# Generate learning curves and validation curves for each combination of hyperparameters\n",
    "suffix_count = 1\n",
    "for params in grid_search.cv_results_['params']:\n",
    "    clf = SVC(**params, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Learning curve\n",
    "    train_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, cv=5, random_state=42)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='g', label='Cross-validation score')\n",
    "    plt.title(f'Learning Curve for {params}')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    learning_curve_path = os.path.join(graphs_dir, f'learning_curve_{params}_suffix{suffix_count}.png'.replace(':', '_').replace(' ', '_').replace(',', '_'))\n",
    "    plt.savefig(learning_curve_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Validation curve for C\n",
    "    param_range = [0.1, 1, 10]\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        clf, X_train, y_train, param_name=\"C\", param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "    plt.plot(param_range, test_scores_mean, 'o-', color='g', label='Validation score')\n",
    "    plt.title(f'Validation Curve for C for {params}')\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    validation_curve_path = os.path.join(graphs_dir, f'validation_curve_C_{params}_suffix{suffix_count}.png'.replace(':', '_').replace(' ', '_').replace(',', '_'))\n",
    "    plt.savefig(validation_curve_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Validation curve for kernel\n",
    "    param_range = ['linear', 'rbf']\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        SVC(C=params['C'], gamma=params['gamma'], random_state=42), X_train, y_train, param_name=\"kernel\", param_range=param_range, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color='r', label='Training score')\n",
    "    plt.plot(param_range, test_scores_mean, 'o-', color='g', label='Validation score')\n",
    "    plt.title(f'Validation Curve for Kernel for {params}')\n",
    "    plt.xlabel('Kernel')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    validation_curve_path = os.path.join(graphs_dir, f'validation_curve_kernel_{params}_suffix{suffix_count}.png'.replace(':', '_').replace(' ', '_').replace(',', '_'))\n",
    "    plt.savefig(validation_curve_path)\n",
    "    plt.close()\n",
    "\n",
    "    suffix_count += 1\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_classes, yticklabels=label_classes)\n",
    "plt.title('Confusion Matrix for Best SVM Model')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "conf_matrix_path = os.path.join(graphs_dir, f'confusion_matrix_best_svm_suffix{suffix_count}.png')\n",
    "plt.savefig(conf_matrix_path)\n",
    "plt.close()\n",
    "\n",
    "# Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "print(\"All tasks completed successfully. Models and graphs are saved in their respective directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
